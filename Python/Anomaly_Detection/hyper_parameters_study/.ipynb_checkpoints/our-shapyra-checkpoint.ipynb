{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "25ca0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Conv1D, Flatten\n",
    "from Gaugi import retrieve_kw, mkdir_p\n",
    "from Gaugi.messenger import Logger\n",
    "from Gaugi.messenger.macros import *\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f2a2a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    modelCol = []\n",
    "    for n in range(10, 15):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(n, input_shape=(100,), activation='tanh', name='dense_layer'))\n",
    "        model.add(Dense(1, activation='linear', name='output_for_inference'))\n",
    "        model.add(Activation('tanh', name='output_for_training'))\n",
    "        modelCol.append(model)\n",
    "    \n",
    "    return  modelCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "76713928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp_func():\n",
    "    from datetime import datetime\n",
    "    dateTimeObj = datetime.now()\n",
    "    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y-%H.%M.%S\")\n",
    "    return timestampStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "92c8ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iter(fun, n_items_per_job, items_lim):\n",
    "    return ([fun(i, n_items_per_job)\n",
    "           if (i+n_items_per_job) <= items_lim \n",
    "           else fun(i, items_lim % n_items_per_job) \n",
    "           for i in range(0, items_lim, n_items_per_job)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "383e328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['Job_v1']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from Gaugi import LoggerStreamable, LoggerRawDictStreamer, RawDictCnv\n",
    "# Just to remove the keras dependence\n",
    "import tensorflow as tf\n",
    "model_from_json = tf.keras.models.model_from_json\n",
    "\n",
    "import json\n",
    "\n",
    "class Job_v1( LoggerStreamable ):\n",
    "\n",
    "    _streamerObj = LoggerRawDictStreamer(toPublicAttrs = {'_metadata','_id' , '_sorts', '_inits', '_models'})\n",
    "    _cnvObj = RawDictCnv(toProtectedAttrs = {'_metadata','_id', '_sorts', '_inits', '_models'})\n",
    "\n",
    "    __version =  1\n",
    "\n",
    "    def __init__( self, **kw ):\n",
    "        LoggerStreamable.__init__(self, kw)\n",
    "        self._sorts  = []\n",
    "        self._inits  = []\n",
    "        self._models = []\n",
    "        self._id     = None\n",
    "        self._metadata = None\n",
    "\n",
    "    def setSorts(self, v):\n",
    "        if type(v) is int:\n",
    "            self._sorts = [v]\n",
    "        else:\n",
    "            self._sorts = v\n",
    "\n",
    "\n",
    "    def setInits(self, v):\n",
    "        if type(v) is int:\n",
    "            self._inits = range(v)\n",
    "        else:\n",
    "            self._inits = v\n",
    "\n",
    "\n",
    "    def getSorts(self):\n",
    "        return self._sorts\n",
    "\n",
    "\n",
    "    def getInits(self):\n",
    "        return self._inits\n",
    "\n",
    "\n",
    "    def setMetadata( self, d):\n",
    "        self._metadata = d\n",
    "\n",
    "\n",
    "    def getMetadata(self):\n",
    "        return self._metadata\n",
    "\n",
    "\n",
    "    def setModels(self, models, id_models):\n",
    "        self._models = list()\n",
    "        if type(models) is not list:\n",
    "            models=[models]\n",
    "        for idx, model in enumerate(models):\n",
    "            self._models.append({'model':  json.loads(model.to_json()), \n",
    "                                'weights': model.get_weights() , \n",
    "                                'id_model': id_models[idx]})\n",
    "\n",
    "\n",
    "    def getModels(self):\n",
    "        # Loop over all keras model\n",
    "        models = []; id_models = []\n",
    "        for d in self._models:\n",
    "            model = model_from_json( json.dumps(d['model'], \n",
    "                                    separators=(',', ':')) , \n",
    "                                    custom_objects={'RpLayer':RpLayer})\n",
    "            model.set_weights( d['weights'] )\n",
    "            models.append( model )\n",
    "            id_models.append( d['id_model'] )\n",
    "        return models, id_models\n",
    "\n",
    "\n",
    "    def setId( self, id ):\n",
    "        self._id = id\n",
    "\n",
    "\n",
    "    def id(self):\n",
    "        return self._id\n",
    "\n",
    "\n",
    "    def save(self, fname):\n",
    "        d = self.toRawObj()\n",
    "        d['__version'] = self.__version\n",
    "        from Gaugi import save\n",
    "        save( d, fname, compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19748f",
   "metadata": {},
   "source": [
    "# Creates the model architeture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "39af4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_model()\n",
    "nInits = 1\n",
    "nInitsPerJob = 1\n",
    "sortBounds = 10\n",
    "nSortsPerJob = 1\n",
    "nModelsPerJob = 1\n",
    "outputFolder = 'job_test2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d317577c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x7fa73ced72e0>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7fa73cecb3d0>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7fa73cf15b50>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7fa73cf36ca0>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7fa73cef1ac0>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59155a63",
   "metadata": {},
   "source": [
    "# Saves the models in .json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e726ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = time_stamp_func()    \n",
    "# creating the job mechanism file first\n",
    "mkdir_p(outputFolder)\n",
    "\n",
    "if type(models) is not list:\n",
    "    models = [models]\n",
    "\n",
    "modelJobsWindowList = create_iter(lambda i, sorts: list(range(i, i+sorts)), \n",
    "                                  nModelsPerJob,\n",
    "                                  len(models))\n",
    "sortJobsWindowList  = create_iter(lambda i, sorts: list(range(i, i+sorts)), \n",
    "                                  nSortsPerJob,\n",
    "                                  sortBounds)\n",
    "initJobsWindowList  = create_iter(lambda i, sorts: list(range(i, i+sorts)), \n",
    "                                  nInitsPerJob, \n",
    "                                  nInits)\n",
    "\n",
    "nJobs = 0 \n",
    "for (model_idx_list, sort_list, init_list) in product(modelJobsWindowList,\n",
    "                                                      sortJobsWindowList, \n",
    "                                                      initJobsWindowList):\n",
    "    job = Job_v1()\n",
    "    # to be user by the database table\n",
    "    job.setId( nJobs )\n",
    "    job.setSorts(sort_list)\n",
    "    job.setInits(init_list)\n",
    "    job.setModels([models[idx] for idx in model_idx_list],  model_idx_list )\n",
    "    # save config file\n",
    "    model_str = 'ml%i.mu%i' %(model_idx_list[0], model_idx_list[-1])\n",
    "    sort_str  = 'sl%i.su%i' %(sort_list[0], sort_list[-1])\n",
    "    init_str  = 'il%i.iu%i' %(init_list[0], init_list[-1])\n",
    "    job.save( outputFolder+'/' + ('job_config.ID_%s.%s_%s_%s.%s') %\n",
    "          ( str(nJobs).zfill(4), model_str, sort_str, init_str, time_stamp) )\n",
    "    nJobs+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af7e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
