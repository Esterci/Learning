{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "oriented-startup",
   "metadata": {},
   "source": [
    "# Implementation of Anomaly detection using Autoencoders\n",
    "Dataset used here is Credit Card Fraud Detection from Kaggle.\n",
    "\n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "earlier-conservative",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "GPU available:  False\n",
      "Keras backend:  tensorflow\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,normalize, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "\n",
    "from keras import backend as K\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"GPU available: \", tf.test.is_gpu_available())\n",
    "print(\"Keras backend: \", K.backend())\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "# Load layers from keras\n",
    "from keras.layers import Dense, Input, Concatenate, Flatten, BatchNormalization, Dropout, LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.losses import binary_crossentropy\n",
    "from Disco_tf import distance_corr\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score\n",
    "RANDOM_SEED = 2021 \n",
    "TEST_PCT = 0.3\n",
    "LABELS = [\"Normal\",\"Fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "driving-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new loss with distance decorrelation\n",
    "def decorr(var_1, var_2, weights,kappa):\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        #return binary_crossentropy(y_true, y_pred) + distance_corr(var_1, var_2, weights)\n",
    "        #return distance_corr(var_1, var_2, weights)\n",
    "        return binary_crossentropy(y_true, y_pred) + kappa * distance_corr(var_1, var_2, weights)\n",
    "        #return binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-niger",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "informational-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ==== Commencing Initiation ====\n",
      "\n",
      "     .Background Loaded...\n",
      "     .Background shape: (543500, 21)\n",
      "     .Signal Loaded...\n",
      "     .Signal shape: (522467, 21)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# ------------------------------------------------------ #\n",
    "# ----------------------- LOADING ---------------------- #\n",
    "# ------------------------------------------------------ #\n",
    "##########################################################\n",
    "# Firstly the model loads the background and signal data, \n",
    "# then it removes the attributes first string line, which \n",
    "# are the column names, in order to avoid NaN values in \n",
    "# the array.\n",
    "\n",
    "print('         ==== Commencing Initiation ====\\n')\n",
    "\n",
    "### Background\n",
    "b_name='Input_Background_1.csv'\n",
    "background = np.genfromtxt(b_name, delimiter=',')\n",
    "background = background[1:,:]\n",
    "print(\"     .Background Loaded...\" )\n",
    "print(\"     .Background shape: {}\".format(background.shape))\n",
    "\n",
    "### Signal\n",
    "s_name='Input_Signal_1.csv'\n",
    "signal = np.genfromtxt(s_name, delimiter=',')\n",
    "signal = signal[1:,:]\n",
    "print(\"     .Signal Loaded...\")\n",
    "print(\"     .Signal shape: {}\\n\".format(signal.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "secure-surgeon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ==== Commencing Initiation ====\n",
      "\n",
      "     .Background Loaded...\n",
      "     .Background shape: (543500, 21)\n",
      "     .Signal Loaded...\n",
      "     .Signal shape: (522467, 21)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Selecting the most pertinent attributes\n",
    "\n",
    "pertinent_features = [2,3,4,6,10,11,12,14,15,16,18,19,20]\n",
    "\n",
    "background = background[:,pertinent_features]\n",
    "signal = signal[:,pertinent_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "written-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# ------------------------------------------------------ #\n",
    "# --------------------- INITIATION --------------------- #\n",
    "# ------------------------------------------------------ #\n",
    "##########################################################\n",
    "\n",
    "# Number of events\n",
    "total = 1000\n",
    "\n",
    "# Percentage of background samples on the testing phase\n",
    "background_percent = 0.99\n",
    "\n",
    "# Percentage of samples on the training phase\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "lonely-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          ==== Initiation Complete ====\n",
      "\n",
      "=*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*==*=\n",
      "      ==== Commencing Data Processing ====\n",
      ".formatted data shape: (1000, 21)\n",
      ".Background shape: (990, 21)\n",
      ".Signal shape: (10, 21)\n",
      ".Normalizing Data\n",
      ".Creating Labels\n"
     ]
    }
   ],
   "source": [
    "print('\\n          ==== Initiation Complete ====\\n')\n",
    "print('=*='*17 )\n",
    "print('      ==== Commencing Data Processing ====')\n",
    "\n",
    "# Percentage of background samples to divide the data-set\n",
    "dat_set_percent = total/len(background)\n",
    "\n",
    "# Reducing background samples\n",
    "_,reduced_background = train_test_split(background, test_size=dat_set_percent)\n",
    "\n",
    "# Iserting the correct number of signal in streaming\n",
    "\n",
    "n_signal_samples = int(len(reduced_background)*(1-background_percent))\n",
    "\n",
    "_,reduced_background = train_test_split(reduced_background, test_size=background_percent)\n",
    "\n",
    "_,reduced_signal = train_test_split(signal, test_size=n_signal_samples/len(signal))\n",
    "\n",
    "# Concatenating Signal and the Background sub-sets\n",
    "\n",
    "data = np.vstack((reduced_background,reduced_signal))\n",
    "\n",
    "print(\".formatted data shape: {}\".format(data.shape))\n",
    "print(\".Background shape: {}\".format(reduced_background.shape))\n",
    "print(\".Signal shape: {}\".format(reduced_signal.shape))\n",
    "\n",
    "# Normalize Data\n",
    "print('.Normalizing Data')\n",
    "data = normalize(data,norm='max',axis=0)\n",
    "\n",
    "# Creating Labels\n",
    "print('.Creating Labels')\n",
    "\n",
    "labels =np.ones((len(data)))\n",
    "labels[:len(reduced_background)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "closing-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = np.array([\"px1\",\"py1\",\"pz1\",\"E1\",\"eta1\",\"phi1\",\"pt1\",\"px2\",\"py2\",\"pz2\",\"E2\",\"eta2\",\n",
    "            \"phi2\",\"pt2\",\"Delta_R\",\"M12\",\"MET\",\"S\",\"C\",\"HT\",\"A\",'Class'])\n",
    "\n",
    "dataset = pd.DataFrame(np.hstack((data,y.reshape(-1,1))),columns = attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-wealth",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "medium-incidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px1</th>\n",
       "      <th>py1</th>\n",
       "      <th>pz1</th>\n",
       "      <th>E1</th>\n",
       "      <th>eta1</th>\n",
       "      <th>phi1</th>\n",
       "      <th>pt1</th>\n",
       "      <th>px2</th>\n",
       "      <th>py2</th>\n",
       "      <th>pz2</th>\n",
       "      <th>...</th>\n",
       "      <th>phi2</th>\n",
       "      <th>pt2</th>\n",
       "      <th>Delta_R</th>\n",
       "      <th>M12</th>\n",
       "      <th>MET</th>\n",
       "      <th>S</th>\n",
       "      <th>C</th>\n",
       "      <th>HT</th>\n",
       "      <th>A</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.277589</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>0.026377</td>\n",
       "      <td>0.075440</td>\n",
       "      <td>0.123993</td>\n",
       "      <td>0.990530</td>\n",
       "      <td>0.243152</td>\n",
       "      <td>0.246212</td>\n",
       "      <td>0.041990</td>\n",
       "      <td>0.042092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053770</td>\n",
       "      <td>0.240896</td>\n",
       "      <td>0.513970</td>\n",
       "      <td>0.127464</td>\n",
       "      <td>0.100790</td>\n",
       "      <td>0.429242</td>\n",
       "      <td>0.892850</td>\n",
       "      <td>0.232146</td>\n",
       "      <td>-0.011184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.142078</td>\n",
       "      <td>-0.288266</td>\n",
       "      <td>-0.106737</td>\n",
       "      <td>0.135047</td>\n",
       "      <td>-0.347722</td>\n",
       "      <td>-0.636646</td>\n",
       "      <td>0.301268</td>\n",
       "      <td>0.085150</td>\n",
       "      <td>0.241988</td>\n",
       "      <td>0.626984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392727</td>\n",
       "      <td>0.247110</td>\n",
       "      <td>0.870703</td>\n",
       "      <td>0.512166</td>\n",
       "      <td>0.328052</td>\n",
       "      <td>0.032046</td>\n",
       "      <td>0.210514</td>\n",
       "      <td>0.289681</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.029950</td>\n",
       "      <td>0.335778</td>\n",
       "      <td>-0.413888</td>\n",
       "      <td>0.417106</td>\n",
       "      <td>-0.738325</td>\n",
       "      <td>0.527033</td>\n",
       "      <td>0.320697</td>\n",
       "      <td>-0.053652</td>\n",
       "      <td>-0.263759</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.564790</td>\n",
       "      <td>0.259248</td>\n",
       "      <td>0.689912</td>\n",
       "      <td>0.307584</td>\n",
       "      <td>0.251161</td>\n",
       "      <td>0.035388</td>\n",
       "      <td>0.314446</td>\n",
       "      <td>0.295198</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.327364</td>\n",
       "      <td>-0.145099</td>\n",
       "      <td>-0.013284</td>\n",
       "      <td>0.090298</td>\n",
       "      <td>-0.048665</td>\n",
       "      <td>-0.858639</td>\n",
       "      <td>0.318118</td>\n",
       "      <td>0.290420</td>\n",
       "      <td>0.072293</td>\n",
       "      <td>-0.104503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077661</td>\n",
       "      <td>0.288641</td>\n",
       "      <td>0.537394</td>\n",
       "      <td>0.172152</td>\n",
       "      <td>0.108110</td>\n",
       "      <td>0.494346</td>\n",
       "      <td>0.776103</td>\n",
       "      <td>0.289624</td>\n",
       "      <td>0.187591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.140210</td>\n",
       "      <td>-0.262674</td>\n",
       "      <td>0.025893</td>\n",
       "      <td>0.082699</td>\n",
       "      <td>0.106878</td>\n",
       "      <td>-0.355409</td>\n",
       "      <td>0.278537</td>\n",
       "      <td>-0.090500</td>\n",
       "      <td>0.260661</td>\n",
       "      <td>0.386593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607399</td>\n",
       "      <td>0.265789</td>\n",
       "      <td>0.635024</td>\n",
       "      <td>0.218646</td>\n",
       "      <td>0.197042</td>\n",
       "      <td>0.108478</td>\n",
       "      <td>0.335253</td>\n",
       "      <td>0.271209</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        px1       py1       pz1        E1      eta1      phi1       pt1  \\\n",
       "0 -0.277589  0.009077  0.026377  0.075440  0.123993  0.990530  0.243152   \n",
       "1 -0.142078 -0.288266 -0.106737  0.135047 -0.347722 -0.636646  0.301268   \n",
       "2 -0.029950  0.335778 -0.413888  0.417106 -0.738325  0.527033  0.320697   \n",
       "3 -0.327364 -0.145099 -0.013284  0.090298 -0.048665 -0.858639  0.318118   \n",
       "4  0.140210 -0.262674  0.025893  0.082699  0.106878 -0.355409  0.278537   \n",
       "\n",
       "        px2       py2       pz2  ...      phi2       pt2   Delta_R       M12  \\\n",
       "0  0.246212  0.041990  0.042092  ...  0.053770  0.240896  0.513970  0.127464   \n",
       "1  0.085150  0.241988  0.626984  ...  0.392727  0.247110  0.870703  0.512166   \n",
       "2 -0.053652 -0.263759  0.039024  ... -0.564790  0.259248  0.689912  0.307584   \n",
       "3  0.290420  0.072293 -0.104503  ...  0.077661  0.288641  0.537394  0.172152   \n",
       "4 -0.090500  0.260661  0.386593  ...  0.607399  0.265789  0.635024  0.218646   \n",
       "\n",
       "        MET         S         C        HT         A  Class  \n",
       "0  0.100790  0.429242  0.892850  0.232146 -0.011184    0.0  \n",
       "1  0.328052  0.032046  0.210514  0.289681  0.004718    0.0  \n",
       "2  0.251161  0.035388  0.314446  0.295198  0.000974    0.0  \n",
       "3  0.108110  0.494346  0.776103  0.289624  0.187591    0.0  \n",
       "4  0.197042  0.108478  0.335253  0.271209  0.005005    0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "downtown-closer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any nulls in the dataset  False\n",
      "-------\n",
      "No. of unique labels  2\n",
      "Label values  [0. 1.]\n",
      "-------\n",
      "Break down of the Normal and Fraud Transactions\n",
      "0.0    990\n",
      "1.0     10\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for any  nullvalues \n",
    "print(\"Any nulls in the dataset \",dataset.isnull().values.any() )\n",
    "print('-------')\n",
    "print(\"No. of unique labels \", len(dataset['Class'].unique()))\n",
    "print(\"Label values \",dataset.Class.unique())\n",
    "#0 is for normal credit card transaction\n",
    "#1 is for fraudulent credit card transaction\n",
    "print('-------')\n",
    "print(\"Break down of the Normal and Fraud Transactions\")\n",
    "print(pd.value_counts(dataset['Class'], sort = True) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-mention",
   "metadata": {},
   "source": [
    "### Visualize the dataset\n",
    "plotting the number of normal and fraud transactions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "moral-olympus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdHUlEQVR4nO3de7wd873/8ddbxCWuIUEkqeCkF7QuDUV/JXU5biWqVWld4vJr6PFTbbUVHlSV/KoXWtqjmhaN0+IEPeSgLU2Fo+oStxLhJ4jYErKpSwQhfH5/zHfXZFt7zSQ7s9ZK1vv5eKzHmvnOrPl+1qy112fP9zvzHUUEZmZm9azU7ADMzKz1OVmYmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFXKysBWapGGSQtLKFdczUlJHlXVUQdKpkn7d7Dh6Q9KRkm5vdhwrukr/gKy5JM0CNgTeyRV/MCLmNCciayZJI4HfRsSQrrKI+L9NC8iWKz6yWPHtHxFr5h6LJYqq/+O2ZcefVfW8j3vmZNGGUrPM8ZIeBx5PZZ+R9ICklyXdIeljufW3lXSfpPmS/lPSlZLOTsve1wSQtv8vaXpVST+WNFvS85IukrR6WjZSUoekkyTNkzRX0lG57awu6VxJT0t6RdLtqewGSSd0q/Pvkg6s87aPljQn1XFSes1Gkl6XtH5uOx+X1Cmpb439tqqkn6btzEnTq3Zb51RJL0iaJenQXPm+kh5J+/BZSd/MLau372dJOlnS34EFkk6TdHW3Os+XdEGaPkrSjFTPk5KOTeVrAH8ANpb0WnpsLOm7kn6b29YBkqanWKZK+ki3WL6Z9vUr6buwWq2d3fW9SJ/9S5KekrRPt23tkZv/Zxy5psOjJD2TXn+cpO1T3S9L+vn7q9TPUlyPSto9t2AdSRenz/5ZSWdL6pOL86+SfiLpH8B3a70fAyLCjxX0AcwC9qhRHsDNwHrA6sB2wDzgE0AfYEx67arAKsDTwNeBvsDngbeBs9O2jgRur7H9f0nTPwUmp7rWAv4b+H5aNhJYBHwvbXtf4HWgf1r+78BUYHCKa+cU0xeAu3L1bQ28CKxS470OS/FcAawBfBTo7NovwI3AV3Lr/wT4WQ/783vAncAGwEDgDuCsbu/lvBTjrsAC4ENp+VzgU2m6P7Bdmu5x3+c+wweAoemz2iTto7XT8j5p2zum+f2AzQGlGF7P1TUS6Oj2nr5L1jQF8MEU857p8/g2MLNrv6ZY7gY2Tp/nDOC4HvbVkWTfky+nGL8CzAFU67vZLY6uz+wiYDXgX4E3gWvTvh+c9tmuuboW8d539BDgFWC9tPxa4Jdkn/8G6T0c2+21J5A1y6/e7L/bVn00PQA/Kvxwsz/I14CX0+PaVB7Abrn1fkH60cuVPZZ+bHbJ/5GnZXdQIlmkH6wFwOa5ZTsBT6XpkcAbwMq55fOAHcmOet8Atq7xvlYF/gEMT/M/Bi7sYR90/fB8OFf2Q+DiNH0I8Nc03Qd4Dtihh209Aeybm98LmJV7L4uANXLLJwGnp+nZwLGkH/ky+z73GR7dbfntwBFpek/giTrfgWuBE3Mx1ksWpwOTcstWAp4FRuZiOazbfryoh3qPBGbm5vulz2Gj3LaKksXg3PIXgUNy89cAX8vV1f07ejdwOFmf3UJySQD4InBL7rWzm/23ujw83Ay14jswItZNjwNz5c/kpjcBTkqH9y9LepnsP9mN0+PZSH9ZydMl6x5I9iNxb267f0zlXV6MiEW5+deBNYEBZP9VPtF9oxGxkOyH+DBJK5H98f9HQSz59/s02fsCuA7YQtJmZD+8r0TE3T1sY2MWf+/57QC8FBELelj+ObIjp6cl3Sppp1Reb9/Xih3gcrL3DPClNA+ApH0k3SnpH2lb+5LtyzIWe38R8W6qe3Bunedy012fVU/+uW5EvJ4m663f3fO56TdqzOe3Ves7ujHZ/u0LzM3t31+SHWF06b5/rQYni/aV/8N6BhifSyrrRkS/iLiCrIljsCTl1v9AbnoBWUIAsn6A3LIXyP6ot8xtd52IKPOD8QJZ08PmPSyfCBwK7A68HhF/K9je0G7xzwGIiDfJEs+hZP+J1ks6c8h+fN63naR/6huoVc89ETGK7Efq2lQn1N/3XboPDX0VMFLSEOCzpGSR+k+uITvS2jAi1iVrZlMP26n7/tJnPpTs6GJZW+x7A2zU04ol1fqOziHbvwuBAbn9u3ZEbJlb10Nvl+BkYQC/Ao6T9All1pC0n6S1gL+RNa98VdLKkg4Cdsi99kFgS0nbpM7O73YtSP+Z/gr4iaQNACQNlrRXUUDptZcA56WO2D6Sdko/iKTk8C5wLsVHFQCnS+onaUvgKOA/c8suI2uOOAD4bY3XdrkCOE3SQEkDgO/UWP9MSatI+hTwGeCqNH+opHUi4m3gVd47nbnevu9p33SS9eVcStakNyMtWoWsia4TWJQ6lP8199LngfUlrdPDpicB+0naXVkH/0lkP7R31NknS+sBYLSkvpJGkPWF9cYGZN/RvpIOBj4C3BgRc4GbgHMlrS1pJUmbS9q1l/W1HScLIyKmkXVE/hx4iaxT88i07C3goDT/Elkb/+9zr/1/ZB2/fyY7s6r7xVEnp+3dKenVtN6HSob2TeAh4B6yPoofsPh39jKyDut6P/Bdbk1xTAF+HBE35d7DX8kSz30RMavONs4GpgF/T3Hdl8q6PEe2j+YAvyPr/H00LTscmJX2wXHAYanuHvd9gcuBPcg1QUXEfOCrZD/6L5E1UU3OLX+ULOE9mZpk8k1dRMRjKa6fkR3Z7U926vVbJeJZUqeTHTW+BJyZfx9L6S5gOFnc44HPR8SLadkRZIn0kVTf1cCgXtbXdrrOTDArTdJvyDpKT2tyHEcAYyPify2Dbf0FuDwiluurmc2q4gtQbLkkqR/wb8CFy2Bb25Odwjqqt9syW1G5GcqWO6nPo5OsDb5XzReSJpI1jX0tNeOYWQ1uhjIzs0I+sjAzs0IrbJ/FgAEDYtiwYc0Ow8xsuXLvvfe+EBEDu5evsMli2LBhTJs2rdlhmJktVyTVHKHBzVBmZlbIycLMzAo5WZiZWaHKkoWkS5Td0ObhXNl6km6W9Hh67p9bdoqkmZIey48dpOxmNA+lZRd0GyzMzMwaoMoji98Ae3crGwdMiYjhZGP0jAOQtAUwGtgyvebCrjtZkY33P5Zs3JfhNbZpZmYVqyxZRMRtZIO/5Y0iG1qa9HxgrvzKiFgYEU+RDaa2g6RBZDeL+Vsaq/6y3GvMzKxBGt1nsWEaMpj03HUDksEsfgOSjlQ2OE13LzczswZqlQ7uWv0QUae89kaksZKmSZrW2dm5zIIzM2t3jU4Wz6emJdLzvFTeweJ3MhtCdk+AjjTdvbymiJgQESMiYsTAge+7ANHMzJZSo6/gngyMAc5Jz9flyi+XdB7ZfXOHA3dHxDuS5kvakezmJkeQ3ZhlhTFs3A3NDmGFMeuc/ZodgtkKq7JkIekKYCQwQFIHcAZZkpgk6RhgNnAwQERMlzSJ7E5Wi4DjI6LrtpNfITuzanXgD+lhZmYNVFmyiIgv9rBo9x7WH092O8Tu5dOArZZhaGZmtoRapYPbzMxamJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMysUFOShaSvS5ou6WFJV0haTdJ6km6W9Hh67p9b/xRJMyU9JmmvZsRsZtbOGp4sJA0GvgqMiIitgD7AaGAcMCUihgNT0jyStkjLtwT2Bi6U1KfRcZuZtbNmNUOtDKwuaWWgHzAHGAVMTMsnAgem6VHAlRGxMCKeAmYCOzQ2XDOz9rZEyUJSf0kf602FEfEs8GNgNjAXeCUibgI2jIi5aZ25wAbpJYOBZ3Kb6EhlteIbK2mapGmdnZ29CdPMzHIKk4WkqZLWlrQe8CBwqaTzlrbC1BcxCtgU2BhYQ9Jh9V5SoyxqrRgREyJiRESMGDhw4NKGaGZm3ZQ5slgnIl4FDgIujYiPA3v0os49gKciojMi3gZ+D+wMPC9pEEB6npfW7wCG5l4/hKzZyszMGqRMslg5/Xh/Abh+GdQ5G9hRUj9JAnYHZgCTgTFpnTHAdWl6MjBa0qqSNgWGA3cvgzjMzKyklUus8z3gT8DtEXGPpM2Ax5e2woi4S9LVwH3AIuB+YAKwJjBJ0jFkCeXgtP50SZOAR9L6x0fEO0tbv5mZLbnCZBERVwFX5eafBD7Xm0oj4gzgjG7FC8mOMmqtPx4Y35s6zcxs6RUmC0kDgS8Dw/LrR8TR1YVlZmatpEwz1HXA/wB/Btz8Y2bWhsoki34RcXLlkZiZWcsqczbU9ZL2rTwSMzNrWWWSxYlkCeNNSfPT49WqAzMzs9ZR5myotRoRiJmZta4yfRZIOgDYJc1OjYhlcXGemZktJ8qMDXUOWVPUI+lxYiozM7M2UebIYl9gm4h4F0DSRLKrrsdVGZiZmbWOskOUr5ubXqeCOMzMrIWVObL4PnC/pFvIhgvfBTil0qjMzKyllDkb6gpJU4HtyZLFyRHxXNWBmZlZ6+ixGUrSh9PzdsAgsvtKPANsnMrMzKxN1Duy+AYwFji3xrIAdqskIjMzazk9JouIGJsm94mIN/PLJK1WaVRmZtZSypwNdUfJMjMzW0H1eGQhaSNgMLC6pG3JOrcB1gb6NSA2MzNrEfX6LPYCjgSGAOflyucDp1YYk5mZtZh6fRYTgYmSPhcR1zQwJjMzazFlrrO4RtJ+wJbAarny71UZmJmZtY4yAwleBBwCnEDWb3EwsEnFcZmZWQspczbUzhFxBPBSRJwJ7AQMrTYsMzNrJWWSxRvp+XVJGwNvA5tWF5KZmbWaMgMJXi9pXeBHwH1kV2//qsqgzMystZTp4D4rTV4j6XpgtYh4pdqwzMyslZTp4H5Q0qmSNo+IhU4UZmbtp0yfxQHAImCSpHskfVPSByqOy8zMWkhhsoiIpyPihxHxceBLwMeApyqPzMzMWkaZDm4kDQO+QHa9xTvAtyuMyczMWkxhspB0F9AXmAQcHBFPVh6VmZm1lLrJQtJKwH9FxDkNisfMzFpQ3T6LiHgX2LdBsZiZWYsqczbUzekMqKGS1ut6VB6ZmZm1jDLJ4mjgeOA24N70mNabSiWtK+lqSY9KmiFpp5SEbpb0eHrun1v/FEkzJT0maa/e1G1mZkuuzKmzm9Z4bNbLes8H/hgRHwa2BmYA44ApETEcmJLmkbQFMJpsiPS9gQsl9ell/WZmtgTKXMHdT9Jpkiak+eGSPrO0FUpaG9gFuBggIt6KiJeBUcDEtNpE4MA0PQq4Ml09/hQwE9hhaes3M7MlV6YZ6lLgLWDnNN8BnN2LOjcDOoFLJd0v6deS1gA2jIi5AOl5g7T+YOCZ3Os7Utn7SBoraZqkaZ2dnb0I0czM8soki80j4odkQ5MTEW+Q3QRpaa0MbAf8IiK2BRaQmpx6UKuuqLViREyIiBERMWLgwIG9CNHMzPLKJIu3JK1O+oGWtDmwsBd1dgAdEXFXmr+aLHk8L2lQqmMQMC+3fv5mS0OAOb2o38zMllCZZHEG8EdgqKTfkXU+L/VwHxHxHPCMpA+lot2BR4DJwJhUNga4Lk1PBkZLWlXSpsBw4O6lrd/MzJZcmftZ3CzpPmBHsiahEyPihV7WewLwO0mrAE8CR5ElrkmSjgFmk93rm4iYLmkSWUJZBBwfEe/0sn4zM1sCZcaG+iTwQETcIOkw4FRJ50fE00tbaUQ8AIyosWj3HtYfD4xf2vrMzKx3yjRD/YLs/ttbA98CngYuqzQqMzNrKWWSxaKICLLrHS6IiPOBtaoNy8zMWkmZ+1nMl3QKcDjwqXT1dN9qwzIzs1ZS5sjiELJTZY9OZzINBn5UaVRmZtZSyowN9RxwOdBf0v7AWxHhPgszszZSZmyo/012XcNBwOeBOyUdXXVgZmbWOsr0WXwL2DYiXgSQtD5wB3BJlYGZmVnrKNNn0QHMz83PZ/GB/czMbAXX45GFpG+kyWeBuyRdRzY+1Cg83IaZWVup1wzVdS3FE+nR5boa65qZ2Qqsx2QREWd2TUtaMyuKBQ2JyszMWkrdPgtJX5E0m2yIj9mSnpb0b40JzczMWkWPyULSacD+wMiIWD8i1gc+DeyTlpmZWZuod2RxOHBQRDzZVZCmvwAcUXVgZmbWOuo2Q0XEmzXK3gDerSwiMzNrOfWSRYek991fQtJuwNzqQjIzs1ZT79TZrwLXSboduJfsGovtgU+SXWthZmZtoscji4iYDmwF3AYMAzZL01ulZWZm1ibqjg2V+iw8BpSZWZsrMzaUmZm1OScLMzMrVO+ivCnp+QeNC8fMzFpRvT6LQZJ2BQ6QdCWg/MKIuK/SyMzMrGXUSxbfAcYBQ4Dzui0LYLeqgjIzs9ZSb9TZq4GrJZ0eEWc1MCYzM2sxhbdVjYizJB0A7JKKpkbE9dWGZWZmraTwbChJ3wdOBB5JjxNTmZmZtYnCIwtgP2CbiHgXQNJE4H7glCoDMzOz1lH2Oot1c9PrVBCHmZm1sDJHFt8H7pd0C9nps7vgowozs7ZSpoP7CklTyUacFXByRDxXdWBmZtY6yhxZEBFzgckVx2JmZi3KY0OZmVmhpiULSX0k3S/p+jS/nqSbJT2envvn1j1F0kxJj0naq1kxm5m1q7rJQtJKkh6uqO4TgRm5+XHAlIgYDkxJ80jaAhgNbAnsDVwoqU9FMZmZWQ11k0W6tuJBSR9YlpVKGkJ2/cavc8WjgIlpeiJwYK78yohYGBFPATOBHZZlPGZmVl+ZDu5BwHRJdwMLugoj4oBe1PtT4NvAWrmyDVNHOhExV9IGqXwwcGduvY5U9j6SxgJjAT7wgWWa38zM2lqZZHHmsqxQ0meAeRFxr6SRZV5SoyxqrRgRE4AJACNGjKi5jpmZLbky11ncKmkTYHhE/FlSP6A3fQafJLtHxr7AasDakn4LPC9pUDqqGATMS+t3AENzrx8CzOlF/WZmtoTKDCT4ZeBq4JepaDBw7dJWGBGnRMSQiBhG1nH9l4g4jOw6jjFptTHAdWl6MjBa0qqSNgWGA3cvbf1mZrbkyjRDHU/WoXwXQEQ8nutPWJbOASZJOgaYDRyc6psuaRLZiLeLgOMj4p0K6jczsx6USRYLI+ItKes6kLQyPfQZLKmImApMTdMvArv3sN54YPyyqNPMzJZcmYvybpV0KrC6pD2Bq4D/rjYsMzNrJWWSxTigE3gIOBa4ETityqDMzKy1lDkb6t10w6O7yJqfHosIn5ZqZtZGCpOFpP2Ai4AnyK552FTSsRHxh6qDMzOz1lCmg/tc4NMRMRNA0ubADYCThZlZmyjTZzGvK1EkT/LeBXNmZtYGejyykHRQmpwu6UZgElmfxcHAPQ2IzczMWkS9Zqj9c9PPA7um6U6g//tXNzOzFVWPySIijmpkIGZm1rrKnA21KXACMCy/fi+HKDczs+VImbOhrgUuJrtq+91KozEzs5ZUJlm8GREXVB6JmZm1rDLJ4nxJZwA3AQu7CiPivsqiMjOzllImWXwUOBzYjfeaoSLNm5lZGyiTLD4LbBYRb1UdjJmZtaYyV3A/CKxbcRxmZtbCyhxZbAg8KukeFu+z8KmzZmZtokyyOKPyKMzMrKWVuZ/FrY0IxMzMWleZK7jn8949t1cB+gILImLtKgMzM7PWUebIYq38vKQDgR2qCsjMzFpPmbOhFhMR1+JrLMzM2kqZZqiDcrMrASN4r1nKzMzaQJmzofL3tVgEzAJGVRKNmZm1pDJ9Fr6vhZlZm6t3W9Xv1HldRMRZFcRjZmYtqN6RxYIaZWsAxwDrA04WZmZtot5tVc/tmpa0FnAicBRwJXBuT68zM7MVT90+C0nrAd8ADgUmAttFxEuNCMzMzFpHvT6LHwEHAROAj0bEaw2LyszMWkq9i/JOAjYGTgPmSHo1PeZLerUx4ZmZWSuo12exxFd3m5nZiskJwczMCjU8WUgaKukWSTMkTZd0YipfT9LNkh5Pz/1zrzlF0kxJj0naq9Exm5m1u2YcWSwCToqIjwA7AsdL2gIYB0yJiOHAlDRPWjYa2BLYG7hQUp8mxG1m1rYaniwiYm5E3Jem5wMzgMFk401NTKtNBA5M06OAKyNiYUQ8BczEQ6SbmTVUU/ssJA0DtgXuAjaMiLmQJRRgg7TaYOCZ3Ms6Ulmt7Y2VNE3StM7OzsriNjNrN01LFpLWBK4BvhYR9U7FVY2ymkOkR8SEiBgRESMGDhy4LMI0MzOalCwk9SVLFL+LiN+n4uclDUrLBwHzUnkHMDT38iHAnEbFamZmzTkbSsDFwIyIOC+3aDIwJk2PAa7LlY+WtKqkTYHhwN2NitfMzMrd/GhZ+yRwOPCQpAdS2anAOcAkSccAs4GDASJiuqRJwCNkZ1IdHxHvNDxqM7M21vBkERG3U7sfAmD3Hl4zHhhfWVBmZlaXr+A2M7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrIwM7NCy02ykLS3pMckzZQ0rtnxmJm1k5WbHUAZkvoA/w7sCXQA90iaHBGPNDcysxXXsHE3NDuEFcqsc/Zrdgi9srwcWewAzIyIJyPiLeBKYFSTYzIzaxvLxZEFMBh4JjffAXyi+0qSxgJj0+xrkh5rQGztYADwQrODKKIfNDsCaxJ/P5etTWoVLi/JQjXK4n0FEROACdWH014kTYuIEc2Ow6wWfz8bY3lphuoAhubmhwBzmhSLmVnbWV6SxT3AcEmbSloFGA1MbnJMZmZtY7lohoqIRZL+D/AnoA9wSURMb3JY7cRNe9bK/P1sAEW8r+nfzMxsMctLM5SZmTWRk4WZmRVysrB/KhpSRZkL0vK/S9quGXFa+5F0iaR5kh7uYbm/mxVzsjBgsSFV9gG2AL4oaYtuq+0DDE+PscAvGhqktbPfAHvXWe7vZsWcLKxLmSFVRgGXReZOYF1JgxodqLWfiLgN+EedVfzdrJiThXWpNaTK4KVYx6wZ/N2smJOFdSkzpEqpYVfMmsDfzYo5WViXMkOqeNgVa1X+blbMycK6lBlSZTJwRDrzZEfglYiY2+hAzWrwd7Niy8VwH1a9noZUkXRcWn4RcCOwLzATeB04qlnxWnuRdAUwEhggqQM4A+gL/m42iof7MDOzQm6GMjOzQk4WZmZWyMnCzMwKOVmYmVkhJwszMyvkZGHWS5I2knSlpCckPSLpRkkf7GmEVLPlka+zMOsFSQL+C5gYEaNT2TbAhs2My2xZ85GFWe98Gng7XRgGQEQ8QG5QO0nDJP2PpPvSY+dUPkjSbZIekPSwpE9J6iPpN2n+IUlfb/g7MqvBRxZmvbMVcG/BOvOAPSPiTUnDgSuAEcCXgD9FxPh0P5F+wDbA4IjYCkDSulUFbrYknCzMqtcX+HlqnnoH+GAqvwe4RFJf4NqIeEDSk8Bmkn4G3ADc1IyAzbpzM5RZ70wHPl6wzteB54GtyY4oVoF/3tBnF+BZ4D8kHRERL6X1pgLHA7+uJmyzJeNkYdY7fwFWlfTlrgJJ2wOb5NZZB5gbEe8Ch5MN1IikTYB5EfEr4GJgO0kDgJUi4hrgdMD3kraW4GYos16IiJD0WeCnksYBbwKzgK/lVrsQuEbSwcAtwIJUPhL4lqS3gdeAI8ju7nappK5/5E6p+j2YleFRZ83MrJCboczMrJCThZmZFXKyMDOzQk4WZmZWyMnCzMwKOVmYmVkhJwszMyv0/wF+E0Ot/Df8owAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing the imbalanced dataset\n",
    "count_classes = pd.value_counts(dataset['Class'], sort = True)\n",
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.xticks(range(len(dataset['Class'].unique())), dataset.Class.unique())\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Observations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-canadian",
   "metadata": {},
   "source": [
    "Visualizing the amount for normal and fraud transactions.\n",
    "\n",
    "# Deixar para uma próxima, colocar bayes aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "black-locator",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Amount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-a3811e405a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Visualize transactionamounts for normal and fraudulent transactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAmount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfraud_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAmount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Fraud'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Amount'"
     ]
    }
   ],
   "source": [
    "#Save the normal and fradulent transactions in separate dataframe\n",
    "normal_dataset = dataset[dataset.Class == 0] \n",
    "fraud_dataset = dataset[dataset.Class == 1]\n",
    "#Visualize transactionamounts for normal and fraudulent transactions\n",
    "bins = np.linspace(200, 2500, 100)\n",
    "plt.hist(normal_dataset.Amount, bins=bins, alpha=1, density=True, label='Normal')\n",
    "plt.hist(fraud_dataset.Amount, bins=bins, alpha=0.5, density=True, label='Fraud')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Transaction amount vs Percentage of transactions\")\n",
    "plt.xlabel(\"Transaction amount (USD)\")\n",
    "plt.ylabel(\"Percentage of transactions\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-tissue",
   "metadata": {},
   "source": [
    "### Create train and test dataset\n",
    "Checking on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-calculator",
   "metadata": {},
   "source": [
    "The last column in the dataset is our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "terminal-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(df):\n",
    "    mu = np.mean(df, axis=0)\n",
    "    variance = np.mean((df - mu)**2, axis=0)\n",
    "    var_dia = np.diag(variance)\n",
    "    k = len(mu)\n",
    "    X = df - mu\n",
    "    p = 1/((2*np.pi)**(k/2)*(np.linalg.det(var_dia)**0.5))* np.exp(-0.5* np.sum(X @ np.linalg.pinv(var_dia) * X,axis=1))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "southwest-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dataset.values\n",
    "# The other data points are the electrocadriogram data\n",
    "data = raw_data[:, 0:-1]\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.3, random_state=2021 ,stratify = labels)\n",
    "\n",
    "p_train = probability(train_data)\n",
    "p_test = probability(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-commission",
   "metadata": {},
   "source": [
    "> Use only normal transactions to train the Autoencoder.\n",
    "\n",
    "Normal data has a value of 0 in the target variable. Using the target variable to create a normal and fraud dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "injured-drunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No. of records in Fraud Train Data= 7\n",
      " No. of records in Normal Train data= 693\n",
      " No. of records in Fraud Test Data= 3\n",
      " No. of records in Normal Test data= 297\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_labels.astype(bool)\n",
    "test_labels = test_labels.astype(bool)\n",
    "#creating normal and fraud datasets\n",
    "normal_train_data = train_data[~train_labels]\n",
    "normal_p_train = p_train[~train_labels]\n",
    "\n",
    "normal_test_data = test_data[~test_labels]\n",
    "normal_p_test = p_test[~test_labels]\n",
    "\n",
    "fraud_train_data = train_data[train_labels]\n",
    "fraud_p_train = p_train[train_labels]\n",
    "\n",
    "fraud_test_data = test_data[test_labels]\n",
    "fraud_p_test = p_test[test_labels]\n",
    "print(\" No. of records in Fraud Train Data=\",len(fraud_train_data))\n",
    "print(\" No. of records in Normal Train data=\",len(normal_train_data))\n",
    "print(\" No. of records in Fraud Test Data=\",len(fraud_test_data))\n",
    "print(\" No. of records in Normal Test data=\",len(normal_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-marketing",
   "metadata": {},
   "source": [
    "### Set the training parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "adapted-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 150\n",
    "batch_size = 200\n",
    "input_dim = normal_train_data.shape[1]\n",
    "encoding_dim = 6\n",
    "hidden_dim_1 = int(encoding_dim / 2) #\n",
    "hidden_dim_2=10  \n",
    "learning_rate = 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-minority",
   "metadata": {},
   "source": [
    "### Create the Autoencoder\n",
    "The architecture of the autoencoder is shown below.\n",
    "\n",
    "![esquema](autoencoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "constant-activation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 21)]              0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 6)                 132       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 21)                147       \n",
      "=================================================================\n",
      "Total params: 397\n",
      "Trainable params: 397\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#input Layer\n",
    "input_layer = tf.keras.layers.Input(shape=(input_dim, ))\n",
    "#Encoder\n",
    "encoder = tf.keras.layers.Dense(encoding_dim, activation=\"tanh\",                                \n",
    "activity_regularizer=tf.keras.regularizers.l2(learning_rate))(input_layer)\n",
    "encoder=tf.keras.layers.Dropout(0.2)(encoder)\n",
    "encoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(hidden_dim_2, activation=tf.nn.leaky_relu)(encoder)\n",
    "# Decoder\n",
    "decoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\n",
    "decoder=tf.keras.layers.Dropout(0.2)(decoder)\n",
    "decoder = tf.keras.layers.Dense(encoding_dim, activation='relu')(decoder)\n",
    "decoder = tf.keras.layers.Dense(input_dim, activation='tanh')(decoder)\n",
    "#Autoencoder\n",
    "autoencoder = tf.keras.Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-smell",
   "metadata": {},
   "source": [
    "### Define the callbacks for checkpoints and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "focal-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
    "                               mode='min', monitor='val_loss', verbose=2, save_best_only=True)\n",
    "# define our early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=10,\n",
    "    verbose=1, \n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-chick",
   "metadata": {},
   "source": [
    "### Compile the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "subsequent-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-parking",
   "metadata": {},
   "source": [
    "### Train the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "czech-campus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 2s 284ms/step - loss: 0.1286 - accuracy: 0.0857 - val_loss: 0.1266 - val_accuracy: 0.2067\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12665, saving model to autoencoder_fraud.h5\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1263 - accuracy: 0.1943 - val_loss: 0.1244 - val_accuracy: 0.1967\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12665 to 0.12442, saving model to autoencoder_fraud.h5\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1223 - accuracy: 0.1942 - val_loss: 0.1227 - val_accuracy: 0.2067\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12442 to 0.12272, saving model to autoencoder_fraud.h5\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1204 - accuracy: 0.1937 - val_loss: 0.1213 - val_accuracy: 0.2400\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12272 to 0.12130, saving model to autoencoder_fraud.h5\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1206 - accuracy: 0.1788 - val_loss: 0.1199 - val_accuracy: 0.2233\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12130 to 0.11994, saving model to autoencoder_fraud.h5\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1188 - accuracy: 0.1748 - val_loss: 0.1186 - val_accuracy: 0.1933\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11994 to 0.11856, saving model to autoencoder_fraud.h5\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1175 - accuracy: 0.1558 - val_loss: 0.1171 - val_accuracy: 0.1567\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.11856 to 0.11711, saving model to autoencoder_fraud.h5\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1148 - accuracy: 0.1408 - val_loss: 0.1156 - val_accuracy: 0.1333\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.11711 to 0.11561, saving model to autoencoder_fraud.h5\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1132 - accuracy: 0.1475 - val_loss: 0.1140 - val_accuracy: 0.1200\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11561 to 0.11402, saving model to autoencoder_fraud.h5\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1118 - accuracy: 0.1353 - val_loss: 0.1124 - val_accuracy: 0.1267\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11402 to 0.11237, saving model to autoencoder_fraud.h5\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1105 - accuracy: 0.1456 - val_loss: 0.1107 - val_accuracy: 0.1400\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.11237 to 0.11067, saving model to autoencoder_fraud.h5\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1092 - accuracy: 0.1536 - val_loss: 0.1089 - val_accuracy: 0.1433\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.11067 to 0.10893, saving model to autoencoder_fraud.h5\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1070 - accuracy: 0.1380 - val_loss: 0.1072 - val_accuracy: 0.1533\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.10893 to 0.10719, saving model to autoencoder_fraud.h5\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1055 - accuracy: 0.1600 - val_loss: 0.1054 - val_accuracy: 0.1667\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.10719 to 0.10544, saving model to autoencoder_fraud.h5\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1044 - accuracy: 0.1526 - val_loss: 0.1037 - val_accuracy: 0.1700\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.10544 to 0.10371, saving model to autoencoder_fraud.h5\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1024 - accuracy: 0.1737 - val_loss: 0.1020 - val_accuracy: 0.1700\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.10371 to 0.10200, saving model to autoencoder_fraud.h5\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1020 - accuracy: 0.1550 - val_loss: 0.1003 - val_accuracy: 0.1700\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.10200 to 0.10034, saving model to autoencoder_fraud.h5\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0997 - accuracy: 0.1506 - val_loss: 0.0987 - val_accuracy: 0.1700\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.10034 to 0.09873, saving model to autoencoder_fraud.h5\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0996 - accuracy: 0.1660 - val_loss: 0.0971 - val_accuracy: 0.1767\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.09873 to 0.09714, saving model to autoencoder_fraud.h5\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0979 - accuracy: 0.1489 - val_loss: 0.0956 - val_accuracy: 0.1833\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.09714 to 0.09561, saving model to autoencoder_fraud.h5\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0970 - accuracy: 0.1594 - val_loss: 0.0941 - val_accuracy: 0.1867\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.09561 to 0.09409, saving model to autoencoder_fraud.h5\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0939 - accuracy: 0.1915 - val_loss: 0.0926 - val_accuracy: 0.1933\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.09409 to 0.09263, saving model to autoencoder_fraud.h5\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0940 - accuracy: 0.2264 - val_loss: 0.0912 - val_accuracy: 0.2167\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.09263 to 0.09119, saving model to autoencoder_fraud.h5\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0908 - accuracy: 0.2480 - val_loss: 0.0898 - val_accuracy: 0.2433\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.09119 to 0.08982, saving model to autoencoder_fraud.h5\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0888 - accuracy: 0.2391 - val_loss: 0.0885 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.08982 to 0.08854, saving model to autoencoder_fraud.h5\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0899 - accuracy: 0.2476 - val_loss: 0.0873 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.08854 to 0.08730, saving model to autoencoder_fraud.h5\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0889 - accuracy: 0.2498 - val_loss: 0.0861 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.08730 to 0.08609, saving model to autoencoder_fraud.h5\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0873 - accuracy: 0.2355 - val_loss: 0.0849 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.08609 to 0.08495, saving model to autoencoder_fraud.h5\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0850 - accuracy: 0.2533 - val_loss: 0.0838 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.08495 to 0.08384, saving model to autoencoder_fraud.h5\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0845 - accuracy: 0.2500 - val_loss: 0.0828 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.08384 to 0.08276, saving model to autoencoder_fraud.h5\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0848 - accuracy: 0.2411 - val_loss: 0.0817 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.08276 to 0.08169, saving model to autoencoder_fraud.h5\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0836 - accuracy: 0.2411 - val_loss: 0.0806 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.08169 to 0.08063, saving model to autoencoder_fraud.h5\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0823 - accuracy: 0.2460 - val_loss: 0.0796 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.08063 to 0.07960, saving model to autoencoder_fraud.h5\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0814 - accuracy: 0.2533 - val_loss: 0.0786 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.07960 to 0.07863, saving model to autoencoder_fraud.h5\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0798 - accuracy: 0.2393 - val_loss: 0.0777 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.07863 to 0.07771, saving model to autoencoder_fraud.h5\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0778 - accuracy: 0.2396 - val_loss: 0.0768 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.07771 to 0.07678, saving model to autoencoder_fraud.h5\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0778 - accuracy: 0.2538 - val_loss: 0.0758 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.07678 to 0.07583, saving model to autoencoder_fraud.h5\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0777 - accuracy: 0.2435 - val_loss: 0.0749 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.07583 to 0.07491, saving model to autoencoder_fraud.h5\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0762 - accuracy: 0.2456 - val_loss: 0.0740 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.07491 to 0.07401, saving model to autoencoder_fraud.h5\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0757 - accuracy: 0.2365 - val_loss: 0.0731 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.07401 to 0.07312, saving model to autoencoder_fraud.h5\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.0767 - accuracy: 0.2336 - val_loss: 0.0723 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.07312 to 0.07228, saving model to autoencoder_fraud.h5\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0741 - accuracy: 0.2498 - val_loss: 0.0715 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.07228 to 0.07147, saving model to autoencoder_fraud.h5\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0750 - accuracy: 0.2541 - val_loss: 0.0707 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.07147 to 0.07072, saving model to autoencoder_fraud.h5\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0734 - accuracy: 0.2583 - val_loss: 0.0701 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.07072 to 0.07005, saving model to autoencoder_fraud.h5\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0721 - accuracy: 0.2473 - val_loss: 0.0694 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.07005 to 0.06942, saving model to autoencoder_fraud.h5\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0706 - accuracy: 0.2475 - val_loss: 0.0687 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.06942 to 0.06872, saving model to autoencoder_fraud.h5\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0717 - accuracy: 0.2513 - val_loss: 0.0680 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.06872 to 0.06800, saving model to autoencoder_fraud.h5\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0721 - accuracy: 0.2380 - val_loss: 0.0674 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.06800 to 0.06741, saving model to autoencoder_fraud.h5\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0711 - accuracy: 0.2460 - val_loss: 0.0668 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.06741 to 0.06682, saving model to autoencoder_fraud.h5\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0699 - accuracy: 0.2521 - val_loss: 0.0663 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.06682 to 0.06628, saving model to autoencoder_fraud.h5\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0699 - accuracy: 0.2545 - val_loss: 0.0658 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.06628 to 0.06577, saving model to autoencoder_fraud.h5\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0688 - accuracy: 0.2413 - val_loss: 0.0653 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.06577 to 0.06528, saving model to autoencoder_fraud.h5\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0697 - accuracy: 0.2426 - val_loss: 0.0647 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.06528 to 0.06475, saving model to autoencoder_fraud.h5\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0681 - accuracy: 0.2523 - val_loss: 0.0643 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.06475 to 0.06427, saving model to autoencoder_fraud.h5\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0689 - accuracy: 0.2453 - val_loss: 0.0638 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.06427 to 0.06384, saving model to autoencoder_fraud.h5\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0679 - accuracy: 0.2395 - val_loss: 0.0634 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.06384 to 0.06345, saving model to autoencoder_fraud.h5\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0677 - accuracy: 0.2510 - val_loss: 0.0631 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.06345 to 0.06309, saving model to autoencoder_fraud.h5\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0655 - accuracy: 0.2423 - val_loss: 0.0627 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.06309 to 0.06274, saving model to autoencoder_fraud.h5\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0656 - accuracy: 0.2373 - val_loss: 0.0624 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.06274 to 0.06238, saving model to autoencoder_fraud.h5\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0646 - accuracy: 0.2350 - val_loss: 0.0620 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.06238 to 0.06202, saving model to autoencoder_fraud.h5\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0649 - accuracy: 0.2548 - val_loss: 0.0617 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.06202 to 0.06166, saving model to autoencoder_fraud.h5\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0654 - accuracy: 0.2433 - val_loss: 0.0614 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.06166 to 0.06135, saving model to autoencoder_fraud.h5\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0640 - accuracy: 0.2400 - val_loss: 0.0611 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.06135 to 0.06107, saving model to autoencoder_fraud.h5\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0638 - accuracy: 0.2416 - val_loss: 0.0608 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.06107 to 0.06079, saving model to autoencoder_fraud.h5\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0651 - accuracy: 0.2535 - val_loss: 0.0605 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.06079 to 0.06052, saving model to autoencoder_fraud.h5\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0653 - accuracy: 0.2381 - val_loss: 0.0602 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.06052 to 0.06022, saving model to autoencoder_fraud.h5\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0651 - accuracy: 0.2393 - val_loss: 0.0600 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.06022 to 0.05996, saving model to autoencoder_fraud.h5\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0644 - accuracy: 0.2490 - val_loss: 0.0597 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.05996 to 0.05967, saving model to autoencoder_fraud.h5\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0626 - accuracy: 0.2460 - val_loss: 0.0595 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.05967 to 0.05948, saving model to autoencoder_fraud.h5\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0620 - accuracy: 0.2408 - val_loss: 0.0593 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.05948 to 0.05934, saving model to autoencoder_fraud.h5\n",
      "Epoch 71/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0629 - accuracy: 0.2370 - val_loss: 0.0591 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.05934 to 0.05913, saving model to autoencoder_fraud.h5\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0634 - accuracy: 0.2468 - val_loss: 0.0589 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.05913 to 0.05892, saving model to autoencoder_fraud.h5\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0635 - accuracy: 0.2436 - val_loss: 0.0587 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.05892 to 0.05868, saving model to autoencoder_fraud.h5\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0625 - accuracy: 0.2440 - val_loss: 0.0584 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05868 to 0.05840, saving model to autoencoder_fraud.h5\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0617 - accuracy: 0.2466 - val_loss: 0.0582 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.05840 to 0.05819, saving model to autoencoder_fraud.h5\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0633 - accuracy: 0.2365 - val_loss: 0.0581 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.05819 to 0.05806, saving model to autoencoder_fraud.h5\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0611 - accuracy: 0.2553 - val_loss: 0.0579 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.05806 to 0.05787, saving model to autoencoder_fraud.h5\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0617 - accuracy: 0.2523 - val_loss: 0.0577 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.05787 to 0.05766, saving model to autoencoder_fraud.h5\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0605 - accuracy: 0.2521 - val_loss: 0.0575 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.05766 to 0.05752, saving model to autoencoder_fraud.h5\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0602 - accuracy: 0.2535 - val_loss: 0.0574 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05752 to 0.05739, saving model to autoencoder_fraud.h5\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0604 - accuracy: 0.2433 - val_loss: 0.0573 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.05739 to 0.05729, saving model to autoencoder_fraud.h5\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.0612 - accuracy: 0.2450 - val_loss: 0.0571 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.05729 to 0.05714, saving model to autoencoder_fraud.h5\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0616 - accuracy: 0.2405 - val_loss: 0.0569 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05714 to 0.05687, saving model to autoencoder_fraud.h5\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0616 - accuracy: 0.2425 - val_loss: 0.0566 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05687 to 0.05658, saving model to autoencoder_fraud.h5\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0604 - accuracy: 0.2385 - val_loss: 0.0563 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.05658 to 0.05633, saving model to autoencoder_fraud.h5\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0609 - accuracy: 0.2511 - val_loss: 0.0562 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.05633 to 0.05616, saving model to autoencoder_fraud.h5\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0608 - accuracy: 0.2430 - val_loss: 0.0561 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.05616 to 0.05609, saving model to autoencoder_fraud.h5\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0611 - accuracy: 0.2485 - val_loss: 0.0560 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05609 to 0.05595, saving model to autoencoder_fraud.h5\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0606 - accuracy: 0.2418 - val_loss: 0.0559 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.05595 to 0.05586, saving model to autoencoder_fraud.h5\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0597 - accuracy: 0.2298 - val_loss: 0.0558 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.05586 to 0.05577, saving model to autoencoder_fraud.h5\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0606 - accuracy: 0.2443 - val_loss: 0.0556 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.05577 to 0.05556, saving model to autoencoder_fraud.h5\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0601 - accuracy: 0.2496 - val_loss: 0.0553 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.05556 to 0.05534, saving model to autoencoder_fraud.h5\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0582 - accuracy: 0.2495 - val_loss: 0.0552 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.05534 to 0.05522, saving model to autoencoder_fraud.h5\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0583 - accuracy: 0.2416 - val_loss: 0.0551 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05522 to 0.05508, saving model to autoencoder_fraud.h5\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0590 - accuracy: 0.2460 - val_loss: 0.0550 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.05508 to 0.05499, saving model to autoencoder_fraud.h5\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0590 - accuracy: 0.2395 - val_loss: 0.0549 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.05499 to 0.05493, saving model to autoencoder_fraud.h5\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0587 - accuracy: 0.2488 - val_loss: 0.0548 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.05493 to 0.05476, saving model to autoencoder_fraud.h5\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0587 - accuracy: 0.2358 - val_loss: 0.0546 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.05476 to 0.05465, saving model to autoencoder_fraud.h5\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0572 - accuracy: 0.2440 - val_loss: 0.0545 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05465 to 0.05446, saving model to autoencoder_fraud.h5\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0582 - accuracy: 0.2460 - val_loss: 0.0544 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.05446 to 0.05435, saving model to autoencoder_fraud.h5\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0570 - accuracy: 0.2506 - val_loss: 0.0543 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.05435 to 0.05428, saving model to autoencoder_fraud.h5\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0580 - accuracy: 0.2515 - val_loss: 0.0542 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.05428 to 0.05417, saving model to autoencoder_fraud.h5\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0580 - accuracy: 0.2471 - val_loss: 0.0540 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.05417 to 0.05396, saving model to autoencoder_fraud.h5\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0573 - accuracy: 0.2416 - val_loss: 0.0537 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.05396 to 0.05369, saving model to autoencoder_fraud.h5\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0576 - accuracy: 0.2463 - val_loss: 0.0535 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.05369 to 0.05347, saving model to autoencoder_fraud.h5\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0585 - accuracy: 0.2550 - val_loss: 0.0533 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.05347 to 0.05330, saving model to autoencoder_fraud.h5\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0571 - accuracy: 0.2404 - val_loss: 0.0533 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.05330 to 0.05326, saving model to autoencoder_fraud.h5\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0565 - accuracy: 0.2457 - val_loss: 0.0533 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.05326\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0568 - accuracy: 0.2415 - val_loss: 0.0532 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.05326 to 0.05321, saving model to autoencoder_fraud.h5\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0581 - accuracy: 0.2589 - val_loss: 0.0530 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.05321 to 0.05298, saving model to autoencoder_fraud.h5\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0573 - accuracy: 0.2384 - val_loss: 0.0528 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.05298 to 0.05279, saving model to autoencoder_fraud.h5\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0582 - accuracy: 0.2644 - val_loss: 0.0527 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.05279 to 0.05270, saving model to autoencoder_fraud.h5\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0564 - accuracy: 0.2514 - val_loss: 0.0525 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.05270 to 0.05255, saving model to autoencoder_fraud.h5\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0564 - accuracy: 0.2524 - val_loss: 0.0524 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.05255 to 0.05243, saving model to autoencoder_fraud.h5\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0558 - accuracy: 0.2574 - val_loss: 0.0523 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.05243 to 0.05234, saving model to autoencoder_fraud.h5\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0561 - accuracy: 0.2459 - val_loss: 0.0522 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.05234 to 0.05223, saving model to autoencoder_fraud.h5\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0556 - accuracy: 0.2544 - val_loss: 0.0521 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.05223 to 0.05206, saving model to autoencoder_fraud.h5\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0559 - accuracy: 0.2525 - val_loss: 0.0518 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.05206 to 0.05179, saving model to autoencoder_fraud.h5\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0552 - accuracy: 0.2504 - val_loss: 0.0516 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.05179 to 0.05164, saving model to autoencoder_fraud.h5\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.0557 - accuracy: 0.2592 - val_loss: 0.0517 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05164\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.0563 - accuracy: 0.2574 - val_loss: 0.0517 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.05164\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0563 - accuracy: 0.2280 - val_loss: 0.0515 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.05164 to 0.05153, saving model to autoencoder_fraud.h5\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0558 - accuracy: 0.2508 - val_loss: 0.0513 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.05153 to 0.05129, saving model to autoencoder_fraud.h5\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0557 - accuracy: 0.2431 - val_loss: 0.0511 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.05129 to 0.05113, saving model to autoencoder_fraud.h5\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0563 - accuracy: 0.2370 - val_loss: 0.0510 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.05113 to 0.05098, saving model to autoencoder_fraud.h5\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0542 - accuracy: 0.2718 - val_loss: 0.0509 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.05098 to 0.05086, saving model to autoencoder_fraud.h5\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.0551 - accuracy: 0.2321 - val_loss: 0.0508 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.05086 to 0.05078, saving model to autoencoder_fraud.h5\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0537 - accuracy: 0.2513 - val_loss: 0.0508 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.05078\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0553 - accuracy: 0.2544 - val_loss: 0.0507 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.05078 to 0.05071, saving model to autoencoder_fraud.h5\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0537 - accuracy: 0.2463 - val_loss: 0.0506 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.05071 to 0.05058, saving model to autoencoder_fraud.h5\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0560 - accuracy: 0.2519 - val_loss: 0.0504 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.05058 to 0.05042, saving model to autoencoder_fraud.h5\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0543 - accuracy: 0.2373 - val_loss: 0.0503 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.05042 to 0.05033, saving model to autoencoder_fraud.h5\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0542 - accuracy: 0.2589 - val_loss: 0.0502 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.05033 to 0.05019, saving model to autoencoder_fraud.h5\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0538 - accuracy: 0.2595 - val_loss: 0.0500 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.05019 to 0.05005, saving model to autoencoder_fraud.h5\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0543 - accuracy: 0.2564 - val_loss: 0.0499 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.05005 to 0.04995, saving model to autoencoder_fraud.h5\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.0537 - accuracy: 0.2390 - val_loss: 0.0498 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.04995 to 0.04979, saving model to autoencoder_fraud.h5\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.0538 - accuracy: 0.2609 - val_loss: 0.0496 - val_accuracy: 0.2567\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.04979 to 0.04961, saving model to autoencoder_fraud.h5\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0535 - accuracy: 0.2555 - val_loss: 0.0495 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.04961 to 0.04948, saving model to autoencoder_fraud.h5\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0537 - accuracy: 0.2620 - val_loss: 0.0493 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.04948 to 0.04932, saving model to autoencoder_fraud.h5\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0542 - accuracy: 0.2441 - val_loss: 0.0492 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.04932 to 0.04924, saving model to autoencoder_fraud.h5\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0525 - accuracy: 0.2588 - val_loss: 0.0492 - val_accuracy: 0.2533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00141: val_loss improved from 0.04924 to 0.04920, saving model to autoencoder_fraud.h5\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0531 - accuracy: 0.2493 - val_loss: 0.0492 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.04920 to 0.04920, saving model to autoencoder_fraud.h5\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0543 - accuracy: 0.2594 - val_loss: 0.0492 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.04920\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0528 - accuracy: 0.2423 - val_loss: 0.0491 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.04920 to 0.04906, saving model to autoencoder_fraud.h5\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.0522 - accuracy: 0.2639 - val_loss: 0.0489 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.04906 to 0.04885, saving model to autoencoder_fraud.h5\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0528 - accuracy: 0.2565 - val_loss: 0.0487 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.04885 to 0.04870, saving model to autoencoder_fraud.h5\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0526 - accuracy: 0.2428 - val_loss: 0.0486 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.04870 to 0.04857, saving model to autoencoder_fraud.h5\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0534 - accuracy: 0.2400 - val_loss: 0.0485 - val_accuracy: 0.2533\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.04857 to 0.04854, saving model to autoencoder_fraud.h5\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0511 - accuracy: 0.2491 - val_loss: 0.0486 - val_accuracy: 0.2600\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04854\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0526 - accuracy: 0.2549 - val_loss: 0.0486 - val_accuracy: 0.2600\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.04854\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(normal_train_data, normal_train_data,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_data, test_data),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, early_stop]\n",
    "                    ).history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-chemistry",
   "metadata": {},
   "source": [
    "Plot training and test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "extreme-survey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-television",
   "metadata": {},
   "source": [
    "# Detect Anomalies on test data\n",
    "> Anomalies are data points where the reconstruction loss is higher\n",
    "\n",
    "To calculate the reconstruction loss on test data, predict the test data and calculate the mean square error between the test data and the reconstructed test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "afraid-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_predictions = autoencoder.predict(test_data)\n",
    "mse = np.mean(np.power(test_data - test_x_predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse,\n",
    "                        'True_class': test_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-slope",
   "metadata": {},
   "source": [
    "Plotting the test data points and their respective reconstruction error sets a threshold value to visualize if the threshold value needs to be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "appreciated-chance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold_fixed = 0.04\n",
    "groups = error_df.groupby('True_class')\n",
    "fig, ax = plt.subplots()\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index, group.Reconstruction_error, marker='o', ms=3.5, linestyle='',\n",
    "            label= \"Fraud\" if name == 1 else \"Normal\")\n",
    "ax.hlines(threshold_fixed, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\n",
    "ax.legend()\n",
    "plt.title(\"Reconstruction error for normal and fraud data\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-equation",
   "metadata": {},
   "source": [
    "Detect anomalies as points where the reconstruction loss is greater than a fixed threshold. Here we see that a value of 52 for the threshold will be good.\n",
    "### Evaluating the performance of the anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "received-consent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy:  0.44666666666666666\n",
      " Recall:  0.6666666666666666\n",
      " Precision:  0.011976047904191617\n"
     ]
    }
   ],
   "source": [
    "threshold_fixed =0.04\n",
    "pred_y = [1 if e > threshold_fixed else 0 for e in error_df.Reconstruction_error.values]\n",
    "error_df['pred'] =pred_y\n",
    "conf_matrix = confusion_matrix(error_df.True_class, pred_y)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()\n",
    "# print Accuracy, precision and recall\n",
    "print(\" Accuracy: \",accuracy_score(error_df['True_class'], error_df['pred']))\n",
    "print(\" Recall: \",recall_score(error_df['True_class'], error_df['pred']))\n",
    "print(\" Precision: \",precision_score(error_df['True_class'], error_df['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-crest",
   "metadata": {},
   "source": [
    "As our dataset is highly imbalanced, we see a high accuracy but a low recall and precision.\n",
    "Things to further improve precision and recall would add more relevant features, different architecture for autoencoder, different hyperparameters, or a different algorithm.\n",
    "# Conclusion:\n",
    "Autoencoder can be used as an anomaly detection algorithm when we have an unbalanced dataset where we have a lot of good examples and only a few anomalies. Autoencoders are trained to minimize reconstruction error. When we train the autoencoders on normal data or good data, we can hypothesize that the anomalies will have higher reconstruction errors than the good or normal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "tropical-modem",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-f91aa76247f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Setup network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# make inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mf_jets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mleps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup network\n",
    "# make inputs\n",
    "jets = Input(shape=X_train[0].shape[1:])\n",
    "f_jets = Flatten()(jets)\n",
    "leps = Input(shape=X_train[1].shape[1:])\n",
    "f_leps = Flatten()(leps)\n",
    "met = Input(shape=X_train[2].shape[1:])\n",
    "i = Concatenate(axis=-1)([f_jets, f_leps, met])\n",
    "sample_weights = Input(shape=(1,))\n",
    "#setup trainable layers\n",
    "d1 = get_block(i, 1024)\n",
    "d2 = get_block(d1, 1024)\n",
    "d3 = get_block(d2, 512)\n",
    "d4 = get_block(d3, 256)\n",
    "d5 = get_block(d4, 128)\n",
    "o = Dense(1, activation=\"sigmoid\")(d5)\n",
    "\n",
    "model = Model(inputs=[jets,leps,met, sample_weights], outputs=o)\n",
    "model.summary()\n",
    "\n",
    "# Compile model\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(optimizer=opt, loss=decorr(jets[:,0,0], o[:,0], sample_weights[:,0]))\n",
    "#model.compile(optimizer=opt, loss=\"binary_crossentropy\")\n",
    "\n",
    "# Train model\n",
    "model.fit(x=X_train, y=y_train, epochs=20, batch_size=10000, validation_split=0.1)\n",
    "\n",
    "# Evaluate model\n",
    "y_train_predict = model.predict(X_train, batch_size=10000)\n",
    "y_test_predict = model.predict(X_test, batch_size=10000)\n",
    "auc_train = roc_auc_score(y_train, y_train_predict)\n",
    "auc_test = roc_auc_score(y_test, y_test_predict)\n",
    "print(\"area under ROC curve (train sample): \", auc_train)\n",
    "print(\"area under ROC curve (test sample): \", auc_test)\n",
    "\n",
    "# plot correlation\n",
    "x = X_test[0][:,0,0]\n",
    "y = y_test_predict[:,0]\n",
    "corr = np.corrcoef(x, y)\n",
    "print(\"correlation \", corr[0][1])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(\"leading jet pt\")\n",
    "plt.ylabel(\"classifier output\")\n",
    "\n",
    "plt.show()\n",
    "#fig.savefig(\"/work/creissel/TTH/sw/CMSSW_9_4_9/src/TTH/DNN/DisCo/corr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "material-thousand",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 21)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 6)            132         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 6)            0           dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 3)            21          dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 10)           40          dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 3)            33          dense_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 3)            0           dense_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 6)            24          dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 21)           147         dense_112[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 397\n",
      "Trainable params: 397\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#input Layer\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "sample_weights = Input(shape=(1,))\n",
    "#Encoder\n",
    "encoder = Dense(encoding_dim, activation=\"sigmoid\",                                \n",
    "activity_regularizer=tf.keras.regularizers.l2(learning_rate))(input_layer)\n",
    "encoder=tf.keras.layers.Dropout(0.2)(encoder)\n",
    "encoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(hidden_dim_2, activation=tf.nn.leaky_relu)(encoder)\n",
    "# Decoder\n",
    "decoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\n",
    "decoder=tf.keras.layers.Dropout(0.2)(decoder)\n",
    "decoder = tf.keras.layers.Dense(encoding_dim, activation='relu')(decoder)\n",
    "decoder = tf.keras.layers.Dense(input_dim, activation='sigmoid')(decoder)\n",
    "#Autoencoder\n",
    "autoencoder = tf.keras.Model(inputs=[input_layer, sample_weights], outputs=decoder)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "above-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
    "                               mode='min', monitor='val_loss', verbose=2, save_best_only=True)\n",
    "# define our early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=10,\n",
    "    verbose=1, \n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "million-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001)\n",
    "autoencoder.compile(optimizer=opt, loss=decorr(input_layer, decoder, sample_weights,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "alert-wheat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:207 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model_17 expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 21) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-521b2804b289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormal_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormal_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:207 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model_17 expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 21) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "autoencoder.fit(x=normal_train_data, y=normal_train_data, epochs=20, batch_size=10000, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "liberal-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 21, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 21, 1), dtype=tf.float32, name='input_25'), name='input_25', description=\"created by layer 'input_25'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-210-1e4005c53823>:7 loss  *\n        return binary_crossentropy(y_true, y_pred) + kappa * distance_corr(var_1, var_2, weights)\n    /home/thiago/Repositories/Learning/Python/Anomaly_Detection/Autoenconder_keras/Disco_tf.py:18 distance_corr  *\n        yy = tf.tile(var_1, [tf.size(var_1)])\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:11471 tile  **\n        tile, (), dict(input=input, multiples=multiples, name=name)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:122 dispatch\n        result = dispatcher.handle(op, args, kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:1450 handle\n        return TFOpLambda(op)(*args, **kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:952 __call__\n        input_list)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1091 _functional_construction_call\n        inputs, input_masks, args, kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:822 _keras_tensor_symbolic_call\n        return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:863 _infer_output_signature\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:1327 _call_wrapper\n        return self._call_wrapper(*args, **kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:1359 _call_wrapper\n        result = self.function(*args, **kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:11468 tile\n        \"Tile\", input=input, multiples=multiples, name=name)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal\n        compute_device)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal\n        op_def=op_def)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2016 __init__\n        control_input_ops, op_def)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Shape must be rank 2 but is rank 1 for '{{node tf.tile_9/Tile}} = Tile[T=DT_FLOAT, Tmultiples=DT_INT32](Placeholder, tf.tile_9/Tile/multiples)' with input shapes: [?,21], [1].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-913d3e45ec07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                     ).history\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-210-1e4005c53823>:7 loss  *\n        return binary_crossentropy(y_true, y_pred) + kappa * distance_corr(var_1, var_2, weights)\n    /home/thiago/Repositories/Learning/Python/Anomaly_Detection/Autoenconder_keras/Disco_tf.py:18 distance_corr  *\n        yy = tf.tile(var_1, [tf.size(var_1)])\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:11471 tile  **\n        tile, (), dict(input=input, multiples=multiples, name=name)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:122 dispatch\n        result = dispatcher.handle(op, args, kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:1450 handle\n        return TFOpLambda(op)(*args, **kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:952 __call__\n        input_list)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1091 _functional_construction_call\n        inputs, input_masks, args, kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:822 _keras_tensor_symbolic_call\n        return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:863 _infer_output_signature\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:1327 _call_wrapper\n        return self._call_wrapper(*args, **kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:1359 _call_wrapper\n        result = self.function(*args, **kwargs)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:11468 tile\n        \"Tile\", input=input, multiples=multiples, name=name)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal\n        compute_device)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal\n        op_def=op_def)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2016 __init__\n        control_input_ops, op_def)\n    /home/thiago/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Shape must be rank 2 but is rank 1 for '{{node tf.tile_9/Tile}} = Tile[T=DT_FLOAT, Tmultiples=DT_INT32](Placeholder, tf.tile_9/Tile/multiples)' with input shapes: [?,21], [1].\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit([normal_train_data,normal_p_train], [normal_train_data,normal_p_train],\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=([test_data,p_test], [test_data,p_test]),\n",
    "                    verbose=1,\n",
    "                    ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split dataset\n",
    "input_dir = \"/work/creissel/DATA/binaryclassifier\"\n",
    "allX = { feat : np.load(input_dir+'/%s.npy' % feat) for feat in [\"jets\",\"leps\",\"met\"] }\n",
    "X = list(allX.values())\n",
    "y = np.load(input_dir+'/target.npy')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "split = train_test_split(*X,y , test_size=0.1, random_state=42)\n",
    "train = [ split[ix] for ix in range(0,len(split),2) ]\n",
    "test = [ split[ix] for ix in range(1,len(split),2) ]\n",
    "X_train, y_train = train[0:3], train[-1]\n",
    "X_test, y_test = test[0:3], test[-1]\n",
    "\n",
    "X_train.append(np.ones(len(y_train)))\n",
    "X_test.append(np.ones(len(y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and split dataset\n",
    "\n",
    "allX = { feat : np.genfromtxt('%s.csv' % feat, delimiter=',') for feat in [\"Input_Background_1\",\n",
    "                                                                           \"Input_Signal_1\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(allx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "allx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "extraordinary-paper",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-97516438b35a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load and split dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m allX = { feat : np.genfromtxt('%s.csv' % feat, delimiter=',') for feat in [\"Input_Background_1\",\n\u001b[0m\u001b[1;32m      4\u001b[0m                                                                            \"Input_Signal_1\"]}\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-228-97516438b35a>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load and split dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m allX = { feat : np.genfromtxt('%s.csv' % feat, delimiter=',') for feat in [\"Input_Background_1\",\n\u001b[0m\u001b[1;32m      4\u001b[0m                                                                            \"Input_Signal_1\"]}\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;31m# Parse each line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2016\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m             \u001b[0mnbvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = list(allX.values())\n",
    "y = np.load(input_dir+'/target.npy')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "split = train_test_split(*X,y , test_size=0.1, random_state=42)\n",
    "train = [ split[ix] for ix in range(0,len(split),2) ]\n",
    "test = [ split[ix] for ix in range(1,len(split),2) ]\n",
    "X_train, y_train = train[0:3], train[-1]\n",
    "X_test, y_test = test[0:3], test[-1]\n",
    "\n",
    "X_train.append(np.ones(len(y_train)))\n",
    "X_test.append(np.ones(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-creature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
